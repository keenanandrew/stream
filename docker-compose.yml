# This is docker-compose.yml
# It contains a bunch of 'services', which roughly correspond to a node / image
# one for kafka, one for prometheus, etc
#
# where is the network defined? that connects them? anonymously?


version: "2.2"
services: # where all the different nodes are defined


  # what's the diff between jobmanager and taskmanager?
  jobmanager:
    container_name: jobmanager
    build:
      context: ./container/flink/
    ports:
      - "8081:8081"
      - "9249:9249"
    command: jobmanager
    volumes:
      - ./code:/opt/flink/code
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: jobmanager        

  taskmanager:
    container_name: taskmanager
    build:
      context: ./container/flink/
    depends_on: # aha here's the diff
      - jobmanager
    command: taskmanager
    ports:
      - "9250:9249"
    volumes:
      - ./code:/opt/flink/code
    scale: 1
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: jobmanager
        taskmanager.numberOfTaskSlots: 2        

  prometheus:
    # prometheus collates the data for the dashboard
    image: prom/prometheus:v2.37.1 # gets the image from here
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml

  grafana:
    # grafana does the dashboard, using info from prometheus
    image: grafana/grafana:8.4.0 # gets the image from here
    container_name: grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=flink # sets the grafana password
    volumes:
      - ./grafana/provisioning/:/etc/grafana/provisioning/

  zookeeper:
    # zookeeper does some kind of coordination
    image: docker.io/bitnami/zookeeper:3.8 # gets the image from here
    container_name: zookeeper
    ports:
      - "2181:2181"
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes

  kafka:
    # kafka takes in the fake data and pumps out two streams, aka 'topics'
    # chunked into neat 'partitions'
    image: docker.io/bitnami/kafka:3.4 # gets the image from here
    container_name: kafka
    ports:
      - "9093:9093"
    environment:
      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181 # the kafka/zookeeper link?
      - KAFKA_ADVERTISED_LISTENERS=INSIDE://:9092,OUTSIDE://:9093
      - KAFKA_CFG_LISTENERS=INSIDE://:9092,OUTSIDE://:9093
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
      - KAFKA_CFG_INTER_BROKER_LISTENER_NAME=INSIDE
      - ALLOW_PLAINTEXT_LISTENER=yes
    depends_on:
      - zookeeper

  postgres:
    # the databases
    # one for user data
    # one for attributed checkout information
    image: debezium/postgres:15
    container_name: postgres
    hostname: postgres
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_DB=postgres
      - POSTGRES_PASSWORD=postgres
    ports:
      - "5432:5432"
    volumes:
      - ./postgres/init.sql:/docker-entrypoint-initdb.d/init.sql # where it starts from
        # so this is how docker can be instructed to initialise a database
        # and now I have an example of an SQL query that sets up a database end-to-end

  datagen:
    build:
      context: ./container/datagen/
    command: python /opt/datagen/gen_fake_data.py 
      # the script that pumps out fake data
      # this is the command to execute that script

    volumes:
      - ./code:/opt/datagen/code
      - ./datagen:/opt/datagen
    container_name: datagen
    restart: on-failure
    depends_on:
      - postgres
      - kafka
